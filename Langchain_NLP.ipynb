{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Approach :\n",
        "The csv file has been loaded into vector db. All descriptive columns have been combined into one. That is the page content and the article id is the metadata column. The user input is expected to be of three types\n",
        "\n",
        "\n",
        "1.   User knows what they are looking for : in that case, search of that item in the database and look for the best match\n",
        "2.   User doesn't have a particular item on their mind : ask some questions, summarise the response and return the best match product to the user\n",
        "3.   User asks as unrelated question : Bot politely declines to provide an answer\n",
        "\n",
        "No. 1 is fairly straightforward as the user's query is put through the Document retrieval module and a match is fetched.\n",
        "No. 2 Langchain buffer memory and summary memory are used to remember and summarise the user's request, convert it to a query tone and then put through the database. The output is then again humanised and shown to the user.\n",
        "\n",
        "In the interest of time, the implementation is really an MVP. I would like to ask if there is anything else the user might want to add. Also, right now the questions for #2 are hardcoded and I would like to switch it out with input and while: true loops."
      ],
      "metadata": {
        "id": "VChWmqQA8swY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Packages"
      ],
      "metadata": {
        "id": "EXDhutAjSBzX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "metadata": {
        "id": "RRYSu48huSUW"
      },
      "outputs": [],
      "source": [
        "!pip -q install langchain openai chromadb"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Libraries"
      ],
      "metadata": {
        "id": "9g1LAkmeL2U8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.schema.messages import SystemMessage\n",
        "from langchain.schema import HumanMessage\n",
        "from langchain.chains import LLMChain,RetrievalQA\n",
        "from langchain.memory import ConversationBufferMemory, ConversationSummaryMemory\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.document_loaders import DataFrameLoader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.prompts import (\n",
        "    ChatPromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        "    MessagesPlaceholder,\n",
        "    SystemMessagePromptTemplate,\n",
        ")"
      ],
      "metadata": {
        "id": "v6vOSICLSG_D"
      },
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparing DB"
      ],
      "metadata": {
        "id": "4phdIGBRMlw-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wtLwvQ90r2YZ",
        "outputId": "d70d4076-041f-4c0d-cd58-319098d1ba6d"
      },
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "articles = pd.read_csv(\"/content/drive/MyDrive/Copy of articles.csv\")\n",
        "print(articles.columns)\n",
        "\n",
        "def concat_columns(df, cols_to_concat, new_col_name, sep=\",\"):\n",
        "    df[new_col_name] = df[cols_to_concat[0]]\n",
        "    for col in cols_to_concat[1:]:\n",
        "        df[new_col_name] = df[new_col_name] + sep + df[col]\n",
        "    return df\n",
        "\n",
        "cols_to_concat = ['prod_name', 'product_type_name', 'product_group_name','graphical_appearance_name', 'colour_group_name', 'garment_group_name','detail_desc']\n",
        "new_col_name = 'concatenated_desc'\n",
        "articles = concat_columns(articles, cols_to_concat, new_col_name, sep=\",\")\n",
        "# articles = articles[:10]\n",
        "print(len(articles))\n",
        "articles.head(n=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "rbd27X5DsOq8",
        "outputId": "8f207e5c-d226-4c59-b34a-0bbed2f72ae2"
      },
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['article_id', 'prod_name', 'product_type_name', 'product_group_name',\n",
            "       'graphical_appearance_name', 'colour_group_name', 'garment_group_name',\n",
            "       'detail_desc'],\n",
            "      dtype='object')\n",
            "1000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   article_id     prod_name product_type_name  product_group_name  \\\n",
              "0   695255001   Siv t-shirt           T-shirt  Garment Upper body   \n",
              "1   821115007  RICHIE SKIRT             Skirt  Garment Lower body   \n",
              "\n",
              "  graphical_appearance_name colour_group_name garment_group_name  \\\n",
              "0          All over pattern         Dark Blue       Jersey Fancy   \n",
              "1                     Check              Pink             Skirts   \n",
              "\n",
              "                                         detail_desc  \\\n",
              "0  Short-sleeved top in soft viscose jersey with ...   \n",
              "1  Short, pleated skirt in woven fabric with a hi...   \n",
              "\n",
              "                                   concatenated_desc  \n",
              "0  Siv t-shirt,T-shirt,Garment Upper body,All ove...  \n",
              "1  RICHIE SKIRT,Skirt,Garment Lower body,Check,Pi...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d67baece-d74e-4b81-862a-f849f49caa7c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>article_id</th>\n",
              "      <th>prod_name</th>\n",
              "      <th>product_type_name</th>\n",
              "      <th>product_group_name</th>\n",
              "      <th>graphical_appearance_name</th>\n",
              "      <th>colour_group_name</th>\n",
              "      <th>garment_group_name</th>\n",
              "      <th>detail_desc</th>\n",
              "      <th>concatenated_desc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>695255001</td>\n",
              "      <td>Siv t-shirt</td>\n",
              "      <td>T-shirt</td>\n",
              "      <td>Garment Upper body</td>\n",
              "      <td>All over pattern</td>\n",
              "      <td>Dark Blue</td>\n",
              "      <td>Jersey Fancy</td>\n",
              "      <td>Short-sleeved top in soft viscose jersey with ...</td>\n",
              "      <td>Siv t-shirt,T-shirt,Garment Upper body,All ove...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>821115007</td>\n",
              "      <td>RICHIE SKIRT</td>\n",
              "      <td>Skirt</td>\n",
              "      <td>Garment Lower body</td>\n",
              "      <td>Check</td>\n",
              "      <td>Pink</td>\n",
              "      <td>Skirts</td>\n",
              "      <td>Short, pleated skirt in woven fabric with a hi...</td>\n",
              "      <td>RICHIE SKIRT,Skirt,Garment Lower body,Check,Pi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d67baece-d74e-4b81-862a-f849f49caa7c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d67baece-d74e-4b81-862a-f849f49caa7c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d67baece-d74e-4b81-862a-f849f49caa7c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2e161ba8-a7db-4550-9edb-1acda1e82889\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2e161ba8-a7db-4550-9edb-1acda1e82889')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2e161ba8-a7db-4550-9edb-1acda1e82889 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loader = DataFrameLoader(articles[['article_id', 'concatenated_desc']],page_content_column=\"concatenated_desc\")\n",
        "data=loader.load()\n",
        "text_splitter = CharacterTextSplitter(chunk_size=250, chunk_overlap=10)\n",
        "texts = text_splitter.split_documents(data)\n",
        "print(len(texts))\n",
        "texts[5]"
      ],
      "metadata": {
        "id": "QYmwce8QsYSY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a7c73a9-af05-4d1f-ad57-73967b646eea"
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content='KELLY SHIRT S.0,Shirt,Garment Upper body,Stripe,Blue,Blouses,Shirt in airy cotton with a collar, buttons down the front, long sleeves with buttoned cuffs, and a rounded hem.', metadata={'article_id': 697564030})"
            ]
          },
          "metadata": {},
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Embed and store the texts\n",
        "# Supplying a persist_directory will store the embeddings on disk\n",
        "persist_directory = 'db'\n",
        "import os\n",
        "\n",
        "## here we are using OpenAI embeddings but in future we will swap out to local embeddings\n",
        "embedding = OpenAIEmbeddings()\n",
        "\n",
        "vectordb = Chroma.from_documents(documents=texts,\n",
        "                                 embedding=embedding,\n",
        "                                 persist_directory=persist_directory)\n",
        "\n",
        "#make a retriever\n",
        "retriever = vectordb.as_retriever(search_kwargs = {\"k\":2})\n",
        "print(retriever.search_type)\n",
        "print(retriever.search_kwargs)"
      ],
      "metadata": {
        "id": "Q_eTIZwf4Dk2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "716e8777-43e7-419b-a78d-10ce09b8d95d"
      },
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "similarity\n",
            "{'k': 2}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functions to modulate AI responses"
      ],
      "metadata": {
        "id": "uvtot4wz4llk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Function to convert AI's summary of user's request into a question\"\"\"\n",
        "def AItoQuestion(input_txt):\n",
        "    llm = ChatOpenAI()\n",
        "    system_prompt_3 = \"\"\"\"the input statement will mention an object description.convert that description from a\n",
        "    statement to a question that looks for the nearest match to the description. for example, if the user says:\n",
        "    you want a new red top, then rephrase it as: is there anything that nearly matches a red top ?\"\"\"\n",
        "\n",
        "\n",
        "    messages = [\n",
        "        SystemMessage(\n",
        "            content=system_prompt_3\n",
        "        ),\n",
        "        HumanMessage(\n",
        "            content=input_txt\n",
        "        ),\n",
        "    ]\n",
        "    op_txt = llm(messages)\n",
        "    return op_txt\n",
        "\n",
        "# get_question = str(AItoQuestion(get_text))[9:]\n",
        "# get_question"
      ],
      "metadata": {
        "id": "-T0f4BAKPl3p"
      },
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Function to convert matched output to conversational tone\"\"\"\n",
        "def ResultsToConversation(input_txt):\n",
        "    llm = ChatOpenAI()\n",
        "    system_prompt_3 = \"\"\"\"the input statement will contain the description of an object followed by a metadata that contains an article id.\n",
        "    convert the input into a human -like message. For example,  if the input is : 'fancy black pants. metadata = {'article_id' : 75657766} ' then rephrase it as :\n",
        "    'here is what i found ! :Fancy black pants, check out article id : 75657766 \"\"\"\n",
        "\n",
        "\n",
        "    messages = [\n",
        "        SystemMessage(content=system_prompt_3),\n",
        "          HumanMessage(content=input_txt)\n",
        "    ]\n",
        "    op_txt = llm(messages)\n",
        "    return op_txt\n",
        "\n",
        "# get_response = str(ResultsToConversation(op_txt))\n",
        "# get_response"
      ],
      "metadata": {
        "id": "FoZ0tQIIC4qY"
      },
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def HelptheUser(firstquestion):\n",
        "\n",
        "    llm = ChatOpenAI()\n",
        "    system_prompt = \"\"\"\"you work as an assistant at a garment store. your goal is to ask the user about the\n",
        "    following:\\n- the occasion they are shopping for\\n- any particular type of garment they want\\n- any preference of colors\\n\\n\n",
        "    Ask for all these preferences from the user one by one and combine the responses in the end in one sentence.\n",
        "    \"\"\"\n",
        "\n",
        "    # Prompt\n",
        "    prompt = ChatPromptTemplate(\n",
        "        messages=[\n",
        "            SystemMessagePromptTemplate.from_template(\n",
        "                system_prompt\n",
        "            ),\n",
        "            MessagesPlaceholder(variable_name=\"chat_history\"),\n",
        "            HumanMessagePromptTemplate.from_template(\"{question}\"),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "    conversation = LLMChain(llm=llm, prompt=prompt, verbose=True, memory=memory)\n",
        "    # conversation({\"question\": \"hi, i want to buy something, can you help me ?\"})\n",
        "    conversation({\"question\": firstquestion})\n",
        "    conversation({\"question\": \"i would like to get something for the beach\"})\n",
        "    conversation({\"question\": \"maybe a bikini\"})\n",
        "    conversation({\"question\": \"shades of blue i like\"})\n",
        "    response = conversation({\"question\": \"yes!\"})\n",
        "    get_text = response['text']\n",
        "    return get_text\n"
      ],
      "metadata": {
        "id": "XWYptZioLceM"
      },
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Function to determine if the user's request is towards a specific product or is looking for advice\"\"\"\n",
        "def usersays(firstlinefromuser):\n",
        "    llm = ChatOpenAI()\n",
        "    system_prompt_3 = \"\"\"\"you are a helpful chatbot with a garment company. if the input statement contains an inquiry about a specific garment then\n",
        "    return 'specific'. if the inquiry is about seeking help with choosing garments then return 'help'. If the user asks anything other than about garments\n",
        "    then reply politely that you do not know about this\"\"\"\n",
        "\n",
        "\n",
        "    messages = [\n",
        "        SystemMessage(content=system_prompt_3),\n",
        "          HumanMessage(content=firstlinefromuser)\n",
        "    ]\n",
        "    op_txt = llm(messages)\n",
        "    return op_txt\n",
        "\n",
        "\"\"\"Accepts the type of user query as input and then passes it along the conversational chain if it is a general advice or towards document retrieval if it is something specific\"\"\"\n",
        "\n",
        "def QueryType(get_response):\n",
        "    qa_chain = RetrievalQA.from_chain_type(llm=OpenAI(),\n",
        "                                  chain_type=\"stuff\",\n",
        "                                  retriever=retriever,\n",
        "                                  return_source_documents=True)\n",
        "    if get_response == 'specific':\n",
        "        llm_response = qa_chain(firstlinefromuser) #passing the generated question into retrieval chain to get the best match\n",
        "        get_question = str(AItoQuestion(str(llm_response['source_documents'][0])))\n",
        "        print(\"Best Match:\")\n",
        "        op_txt = str(llm_response['source_documents'][0])[9:]\n",
        "        final_response = str(ResultsToConversation(op_txt))\n",
        "\n",
        "\n",
        "    elif get_response == 'help':\n",
        "      op_txt = HelptheUser(firstlinefromuser)\n",
        "      get_question = str(AItoQuestion(op_txt))\n",
        "      llm_response = qa_chain(get_question)\n",
        "      op_txt = str(llm_response['source_documents'][0])[9:]\n",
        "      final_response = str(ResultsToConversation(op_txt))\n",
        "\n",
        "    else:\n",
        "      final_response = get_response\n",
        "\n",
        "\n",
        "\n",
        "    print(final_response)"
      ],
      "metadata": {
        "id": "iojY1AQGWo6R"
      },
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Putting it all together"
      ],
      "metadata": {
        "id": "l88SnrOj67D_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# firstlinefromuser = \"Do you have a red dress for a party ?\"\n",
        "firstlinefromuser = \"Can you help me choose clothes ?\"\n",
        "\n",
        "get_response = str(usersays(firstlinefromuser))[9:-1]\n",
        "QueryType(get_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "td0UCs5I19is",
        "outputId": "52077875-4c79-4c22-ee45-bb3a78a322a6"
      },
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: \"you work as an assistant at a garment store. your goal is to ask the user about the\n",
            "    following:\n",
            "- the occasion they are shopping for\n",
            "- any particular type of garment they want\n",
            "- any preference of colors\n",
            "\n",
            "\n",
            "    Ask for all these preferences from the user one by one and combine the responses in the end in one sentence.\n",
            "    \n",
            "Human: Can you help me choose clothes ?\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: \"you work as an assistant at a garment store. your goal is to ask the user about the\n",
            "    following:\n",
            "- the occasion they are shopping for\n",
            "- any particular type of garment they want\n",
            "- any preference of colors\n",
            "\n",
            "\n",
            "    Ask for all these preferences from the user one by one and combine the responses in the end in one sentence.\n",
            "    \n",
            "Human: Can you help me choose clothes ?\n",
            "AI: Of course! I'd be happy to help you choose clothes. Could you please tell me the occasion you are shopping for?\n",
            "Human: i would like to get something for the beach\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: \"you work as an assistant at a garment store. your goal is to ask the user about the\n",
            "    following:\n",
            "- the occasion they are shopping for\n",
            "- any particular type of garment they want\n",
            "- any preference of colors\n",
            "\n",
            "\n",
            "    Ask for all these preferences from the user one by one and combine the responses in the end in one sentence.\n",
            "    \n",
            "Human: Can you help me choose clothes ?\n",
            "AI: Of course! I'd be happy to help you choose clothes. Could you please tell me the occasion you are shopping for?\n",
            "Human: i would like to get something for the beach\n",
            "AI: Great! So you're looking for something for the beach. Is there any particular type of garment you have in mind?\n",
            "Human: maybe a bikini\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: \"you work as an assistant at a garment store. your goal is to ask the user about the\n",
            "    following:\n",
            "- the occasion they are shopping for\n",
            "- any particular type of garment they want\n",
            "- any preference of colors\n",
            "\n",
            "\n",
            "    Ask for all these preferences from the user one by one and combine the responses in the end in one sentence.\n",
            "    \n",
            "Human: Can you help me choose clothes ?\n",
            "AI: Of course! I'd be happy to help you choose clothes. Could you please tell me the occasion you are shopping for?\n",
            "Human: i would like to get something for the beach\n",
            "AI: Great! So you're looking for something for the beach. Is there any particular type of garment you have in mind?\n",
            "Human: maybe a bikini\n",
            "AI: Got it, a bikini for the beach. And do you have any preference for colors?\n",
            "Human: shades of blue i like\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: \"you work as an assistant at a garment store. your goal is to ask the user about the\n",
            "    following:\n",
            "- the occasion they are shopping for\n",
            "- any particular type of garment they want\n",
            "- any preference of colors\n",
            "\n",
            "\n",
            "    Ask for all these preferences from the user one by one and combine the responses in the end in one sentence.\n",
            "    \n",
            "Human: Can you help me choose clothes ?\n",
            "AI: Of course! I'd be happy to help you choose clothes. Could you please tell me the occasion you are shopping for?\n",
            "Human: i would like to get something for the beach\n",
            "AI: Great! So you're looking for something for the beach. Is there any particular type of garment you have in mind?\n",
            "Human: maybe a bikini\n",
            "AI: Got it, a bikini for the beach. And do you have any preference for colors?\n",
            "Human: shades of blue i like\n",
            "AI: Perfect! So you are looking for a bikini in shades of blue for the beach. I will keep that in mind while assisting you.\n",
            "Human: yes!\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "content='Here is what I found! Love Shack tanga swimwear bottom in a solid light yellow color. It is fully lined with a low waist and has a frill at the sides. Check out the article id: 560214003.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "firstlinefromuser = \"Do you have a red dress for a party ?\"\n",
        "get_response = str(usersays(firstlinefromuser))[9:-1]\n",
        "QueryType(get_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pV25QSOz8FcO",
        "outputId": "e5cac2e8-a904-40f6-bb09-b258549fcb90"
      },
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Match:\n",
            "content=\"Here is what I found! A beautiful paint dress for ladies. This dress is full body and made of solid, light red chiffon. It features a deep V-neck decorated with a pleated flounce that extends over each shoulder and down the back, transforming into narrow ribbons that cross and tie. There is a seam under the bust, a concealed zip on one side, and a flared, pleated skirt. The dress also comes with a satin lining. Don't miss out on this stunning piece! Check out the article id: 854232002.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "firstlinefromuser = \"Which house should i live in?\"\n",
        "get_response = str(usersays(firstlinefromuser))[9:-1]\n",
        "QueryType(get_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ND2OqoXO9HtV",
        "outputId": "c9b17c65-8b65-4183-a909-ba70efd481d0"
      },
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I'm sorry, but I don't have information about which house you should live in. My expertise is in helping with garment-related inquiries. Is there anything specific about garments that I can assist you with?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o57y8HVd-Iqb"
      },
      "execution_count": 174,
      "outputs": []
    }
  ]
}